# ğŸ§  Neuromorphe Traum-Engine v2.0

*Semantic Audio Search with CLAP Embeddings*

## ğŸ“‹ Ãœbersicht

Die Neuromorphe Traum-Engine v2.0 ist eine moderne, semantische Audio-Suchmaschine, die CLAP (Contrastive Language-Audio Pre-training) Embeddings verwendet, um natÃ¼rlichsprachliche Suchanfragen in Audio-Inhalten zu ermÃ¶glichen. Das System kombiniert eine FastAPI-Backend-Architektur mit einem benutzerfreundlichen Streamlit-Frontend.

## âœ¨ Features

### ğŸµ Audio-Verarbeitung
- **Multi-Format-Support**: WAV, MP3, FLAC, OGG, M4A
- **Automatische Metadaten-Extraktion**: BPM, Dauer, Sampling-Rate
- **CLAP-Embedding-Generierung**: Semantische Audio-ReprÃ¤sentationen
- **Batch-Verarbeitung**: Effiziente Verarbeitung mehrerer Dateien

### ğŸ” Semantische Suche
- **Text-zu-Audio-Suche**: NatÃ¼rlichsprachliche Suchanfragen
- **Ã„hnlichkeitssuche**: Finde Ã¤hnliche Audio-Dateien
- **Erweiterte Filter**: Kategorie, BPM-Bereich, Ã„hnlichkeitsschwelle
- **Fuzzy-Suche**: Tolerante Textsuche

### ğŸ“Š Analytics & Statistiken
- **Suchstatistiken**: Anzahl Dateien, Kategorien, Embeddings
- **Performance-Metriken**: Suchzeiten, Cache-Effizienz
- **Kategorie-Analyse**: Verteilung und Trends

### ğŸ¨ BenutzeroberflÃ¤che
- **Moderne Streamlit-UI**: Responsive und intuitiv
- **Real-time Updates**: Live-Status und Fortschrittsanzeigen
- **Export-Funktionen**: CSV, JSON, Dateilisten
- **Konfigurierbare Einstellungen**: Backend-Verbindung, Suchparameter

## ğŸ—ï¸ Architektur

### Backend (FastAPI)
```
src/
â”œâ”€â”€ api/                 # API Router und Endpunkte
â”œâ”€â”€ audio/              # Audio-Verarbeitung und -Management
â”œâ”€â”€ search/             # Semantische Suchlogik
â”œâ”€â”€ database/           # SQLite-Datenbankoperationen
â””â”€â”€ main.py            # FastAPI-Anwendung
```

### Frontend (Streamlit)
```
pages/
â”œâ”€â”€ audio_upload.py     # Audio-Upload und -Verarbeitung
â”œâ”€â”€ search.py          # Suchinterface
â”œâ”€â”€ results.py         # Ergebnisanzeige
â””â”€â”€ settings.py        # Anwendungseinstellungen
```

## ğŸš€ Installation

### Voraussetzungen
- Python 3.8+
- Git
- Mindestens 4GB RAM (fÃ¼r CLAP-Modell)

### Setup

1. **Repository klonen**
```bash
git clone <repository-url>
cd neuromorphe-traum-engine
```

2. **Virtual Environment erstellen**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Dependencies installieren**
```bash
pip install -r requirements.txt
```

4. **Verzeichnisstruktur erstellen**
```bash
mkdir -p data/audio data/embeddings data/database
```

## ğŸ¯ Verwendung

### Backend starten
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Frontend starten
```bash
streamlit run streamlit_app.py
```

### API-Dokumentation
Nach dem Start des Backends ist die interaktive API-Dokumentation verfÃ¼gbar unter:
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## ğŸ“¡ API-Endpunkte

### Audio-Management
- `POST /api/audio/upload` - Audio-Datei hochladen
- `GET /api/audio/files` - Alle Audio-Dateien auflisten
- `GET /api/audio/files/{file_id}` - Datei-Details abrufen
- `POST /api/audio/files/{file_id}/process` - Embedding generieren
- `GET /api/audio/files/{file_id}/embedding` - Embedding abrufen

### Semantische Suche
- `POST /api/search/text` - Text-zu-Audio-Suche
- `POST /api/search/similar` - Ã„hnlichkeitssuche
- `GET /api/search/stats` - Suchstatistiken
- `GET /api/search/categories` - VerfÃ¼gbare Kategorien

### System
- `GET /api/health` - System-GesundheitsprÃ¼fung
- `GET /api/audio/health` - Audio-Service-Status
- `GET /api/search/health` - Search-Service-Status

## ğŸ”§ Konfiguration

### Umgebungsvariablen
```bash
# Backend-Konfiguration
BACKEND_HOST=localhost
BACKEND_PORT=8000

# Verzeichnisse
AUDIO_DIR=./data/audio
EMBEDDINGS_DIR=./data/embeddings
DATABASE_PATH=./data/database/audio_files.db

# CLAP-Modell
CLAP_MODEL_VERSION=630k-audioset-best

# Upload-Limits
MAX_FILE_SIZE=100MB
ALLOWED_EXTENSIONS=wav,mp3,flac,ogg,m4a
```

### Streamlit-Konfiguration
```toml
# .streamlit/config.toml
[server]
port = 8501
maxUploadSize = 100

[theme]
primaryColor = "#FF6B6B"
backgroundColor = "#FFFFFF"
secondaryBackgroundColor = "#F0F2F6"
textColor = "#262730"
```

## ğŸ§ª Testing

### Unit Tests ausfÃ¼hren
```bash
pytest tests/ -v
```

### API Tests
```bash
pytest tests/test_api.py -v
```

### Integration Tests
```bash
pytest tests/test_integration.py -v
```

## ğŸ“Š Performance

### Benchmarks
- **Audio-Upload**: ~2-5s pro Datei (abhÃ¤ngig von GrÃ¶ÃŸe)
- **Embedding-Generierung**: ~10-30s pro Datei (GPU empfohlen)
- **Suchzeit**: <1s fÃ¼r 1000+ Dateien
- **Speicherverbrauch**: ~2-4GB (CLAP-Modell geladen)

### Optimierungen
- **GPU-Beschleunigung**: CUDA-Support fÃ¼r CLAP-Modell
- **Caching**: LRU-Cache fÃ¼r hÃ¤ufige Suchanfragen
- **Batch-Processing**: Parallele Embedding-Generierung
- **Database-Indizierung**: Optimierte SQLite-Abfragen

## ğŸ› ï¸ Entwicklung

### Code-Struktur
- **Domain-Driven Design**: Modulare Architektur
- **Dependency Injection**: Lose gekoppelte Services
- **Async/Await**: Asynchrone Verarbeitung
- **Type Hints**: VollstÃ¤ndige Typisierung
- **Pydantic**: Datenvalidierung und -serialisierung

### Beitragen
1. Fork des Repositories
2. Feature-Branch erstellen (`git checkout -b feature/amazing-feature`)
3. Ã„nderungen committen (`git commit -m 'Add amazing feature'`)
4. Branch pushen (`git push origin feature/amazing-feature`)
5. Pull Request erstellen

## Projektstruktur

```
Neuromorphe Traum-Engine v2.0/
â”œâ”€â”€ Construction_Plans/          # Projektdirektiven und Architektur
â”‚   â”œâ”€â”€ AGENTEN_DIREKTIVE_001.md
â”‚   â”œâ”€â”€ AGENTEN_DIREKTIVE_002.md
â”‚   â”œâ”€â”€ AGENTEN_DIREKTIVE_003.md
â”‚   â”œâ”€â”€ AGENTEN_DIREKTIVE_004.md
â”‚   â”œâ”€â”€ AGENTEN_DIREKTIVE_005_(MASTER_MVP_auf_bestehender_Architektur).md
â”‚   â”œâ”€â”€ AGENTEN_DIREKTIVE_006.md
â”‚   â”œâ”€â”€ AGENTEN_DIREKTIVE_007_(MASTER_MVP).md
â”‚   â””â”€â”€ AGENTEN_DIREKTIVE_008
â”œâ”€â”€ ai_agents/                   # Hauptkomponenten des Systems
â”‚   â”œâ”€â”€ minimal_preprocessor.py  # Einfacher CLAP-Embedding Preprocessor
â”‚   â”œâ”€â”€ optimized_preprocessor.py
â”‚   â”œâ”€â”€ prepare_dataset_sql.py   # Erweiterte SQL-basierte Verarbeitung
â”‚   â”œâ”€â”€ search_engine_cli.py     # Kommandozeilen-Suchinterface
â”‚   â””â”€â”€ test_prepare_dataset.py
â”œâ”€â”€ raw_construction_kits/       # Input-Verzeichnis fÃ¼r Audio-Dateien
â”œâ”€â”€ processed_database/          # Output-Verzeichnis fÃ¼r verarbeitete Daten
â”œâ”€â”€ requirements.txt             # Python-AbhÃ¤ngigkeiten
â””â”€â”€ [verschiedene Test- und Validierungsskripte]
```

## Kernkomponenten

### 1. Minimal Preprocessor (`ai_agents/minimal_preprocessor.py`)

**Zweck**: Erstellt CLAP-Embeddings fÃ¼r Audio-Dateien und speichert sie in einer kompakten BinÃ¤rdatei.

**FunktionalitÃ¤t**:
- LÃ¤dt das LAION-CLAP-Modell
- Durchsucht rekursiv alle .wav-Dateien im Input-Verzeichnis
- Verarbeitet Audio-Dateien in Batches (StandardgrÃ¶ÃŸe: 32)
- Speichert Embeddings als Pickle-Datei (`processed_database/embeddings.pkl`)

**Verwendung**:
```bash
python ai_agents/minimal_preprocessor.py
```

### 2. Search Engine CLI (`ai_agents/search_engine_cli.py`)

**Zweck**: Interaktive Kommandozeilen-Suchmaschine fÃ¼r semantische Audio-Suche.

**FunktionalitÃ¤t**:
- LÃ¤dt vorverarbeitete CLAP-Embeddings
- Berechnet Text-Embeddings fÃ¼r Benutzer-Prompts
- Findet die Ã¤hnlichsten Audio-Dateien mittels Kosinus-Ã„hnlichkeit
- Gibt Top-5 Ergebnisse mit Ã„hnlichkeitswerten aus

**Verwendung**:
```bash
python ai_agents/search_engine_cli.py
```

**Beispiel-Prompts**:
- "dark industrial kick with heavy bass"
- "melodic synth pad"
- "punchy snare with reverb"

### 3. SQL-basierter Preprocessor (`ai_agents/prepare_dataset_sql.py`)

**Zweck**: Erweiterte Verarbeitung mit SQLite-Datenbank und zusÃ¤tzlichen Metadaten.

**FunktionalitÃ¤t**:
- Erstellt SQLite-Datenbank (`processed_database/stems.db`)
- Extrahiert umfangreiche Audio-Metadaten (BPM, Tonart, etc.)
- Speichert CLAP-Embeddings in der Datenbank
- Implementiert robuste Batch-Verarbeitung mit Resume-FunktionalitÃ¤t
- Kategorisiert Audio-Dateien automatisch

## Installation und Setup

### Voraussetzungen
- Python 3.8+
- CUDA-kompatible GPU (empfohlen fÃ¼r bessere Performance)

### Installation

1. **Repository klonen/herunterladen**

2. **AbhÃ¤ngigkeiten installieren**:
```bash
pip install -r requirements.txt
```

3. **Verzeichnisstruktur erstellen**:
```bash
mkdir raw_construction_kits
mkdir processed_database
```

## Verwendung

### Schnellstart (Minimal MVP)

1. **Audio-Dateien hinzufÃ¼gen**:
   - Legen Sie .wav-Dateien in den Ordner `raw_construction_kits/`

2. **Embeddings erstellen**:
```bash
python ai_agents/minimal_preprocessor.py
```

3. **Suche starten**:
```bash
python ai_agents/search_engine_cli.py
```

### Erweiterte Verwendung (SQL-basiert)

1. **Audio-Dateien verarbeiten**:
```bash
python ai_agents/prepare_dataset_sql.py
```

2. **Erweiterte Suche** (falls implementiert):
```bash
python search_engine_cli.py
```

## AbhÃ¤ngigkeiten

### Kern-Bibliotheken
- **librosa** (â‰¥0.10.0): Audio-Analyse und -Verarbeitung
- **laion-clap**: CLAP-Modell fÃ¼r Audio-Text-Embeddings
- **torch** (â‰¥1.9.0): PyTorch fÃ¼r Deep Learning
- **numpy** (â‰¥1.21.0): Numerische Berechnungen
- **soundfile** (â‰¥0.12.0): Audio-Dateien lesen/schreiben
- **scikit-learn** (â‰¥1.0.0): Machine Learning Algorithmen
- **tqdm**: Fortschrittsanzeige

### Standard-Python-Bibliotheken
- sqlite3, os, logging, datetime, shutil, concurrent.futures, typing, hashlib, pathlib, json

## Architektur

### CLAP-Embeddings
Das System basiert auf LAION-CLAP (Contrastive Language-Audio Pre-training), einem multimodalen Modell, das:
- Audio-Signale in hochdimensionale VektorrÃ¤ume einbettet
- Text-Beschreibungen in denselben Vektorraum projiziert
- Semantische Ã„hnlichkeit durch Kosinus-Ã„hnlichkeit berechnet

### Verarbeitungspipeline
1. **Audio-Eingabe**: .wav-Dateien im `raw_construction_kits/` Verzeichnis
2. **Preprocessing**: Extraktion von CLAP-Embeddings
3. **Speicherung**: Pickle-Datei oder SQLite-Datenbank
4. **Suche**: Text-zu-Audio-Matching via Embedding-Ã„hnlichkeit

## Konfiguration

### Batch-Verarbeitung
- **Batch-GrÃ¶ÃŸe**: 32 (anpassbar in `minimal_preprocessor.py`)
- **Retry-Mechanismus**: Automatische Wiederholung bei Fehlern
- **Checkpoint-System**: Resume-FunktionalitÃ¤t fÃ¼r groÃŸe DatensÃ¤tze

### Performance-Optimierung
- **GPU-Beschleunigung**: Automatische CUDA-Nutzung wenn verfÃ¼gbar
- **Parallele Verarbeitung**: Multi-Threading fÃ¼r I/O-Operationen
- **Speicher-Effizienz**: Batch-weise Verarbeitung groÃŸer DatensÃ¤tze

## Entwicklung und Testing

### Test-Skripte
- `test_implementation.py`: Allgemeine Implementierungstests
- `test_mvp_system.py`: MVP-System-Tests
- `validate_directive_003.py`: Validierung spezifischer Direktiven
- `validate_directive_004.py`: Weitere Direktiven-Validierung

### Debugging-Tools
- `check_db.py`: Datenbank-IntegritÃ¤tsprÃ¼fung
- `check_paths.py`: Pfad-Validierung
- `verify_clap_embeddings.py`: CLAP-Embedding-Verifikation

## Fehlerbehebung

### HÃ¤ufige Probleme

1. **CLAP-Modell lÃ¤dt nicht**:
   - ÃœberprÃ¼fen Sie die Internetverbindung (Modell wird beim ersten Start heruntergeladen)
   - Stellen Sie sicher, dass genÃ¼gend Speicherplatz verfÃ¼gbar ist

2. **Keine Audio-Dateien gefunden**:
   - ÃœberprÃ¼fen Sie, dass .wav-Dateien im `raw_construction_kits/` Verzeichnis liegen
   - Stellen Sie sicher, dass die Dateien gÃ¼ltige Audio-Formate sind

3. **Speicher-Probleme**:
   - Reduzieren Sie die Batch-GrÃ¶ÃŸe in der Konfiguration
   - Verwenden Sie die SQL-basierte Verarbeitung fÃ¼r groÃŸe DatensÃ¤tze

4. **Performance-Probleme**:
   - Stellen Sie sicher, dass CUDA verfÃ¼gbar ist fÃ¼r GPU-Beschleunigung
   - ÃœberprÃ¼fen Sie die verfÃ¼gbaren Systemressourcen

### Logs und Debugging
- Logs werden in der Konsole ausgegeben
- Detaillierte Fehlerinformationen in `processed_database/checkpoints/failed_files.json`
- Progress-Tracking in `processed_database/checkpoints/progress.json`

## Roadmap und Erweiterungen

### Geplante Features
- Web-basierte BenutzeroberflÃ¤che
- Erweiterte Audio-Metadaten-Extraktion
- Batch-Export-FunktionalitÃ¤t
- Plugin-System fÃ¼r DAWs
- Cloud-basierte Verarbeitung

### Experimentelle Features
- Automatische Tag-Generierung
- Cluster-basierte Kategorisierung
- QualitÃ¤tsbewertung von Audio-Dateien
- Benutzer-Rating-System

## Lizenz und BeitrÃ¤ge

Dieses Projekt ist Teil der Neuromorphe Traum-Engine Initiative. BeitrÃ¤ge sind willkommen - bitte folgen Sie den Coding-Standards und erstellen Sie Tests fÃ¼r neue Features.

## Support

FÃ¼r technische Fragen und Support:
1. ÃœberprÃ¼fen Sie die Dokumentation und hÃ¤ufigen Probleme
2. Schauen Sie in die Construction_Plans fÃ¼r detaillierte Architektur-Informationen
3. Erstellen Sie ein Issue mit detaillierter Problembeschreibung

---

*Neuromorphe Traum-Engine v2.0 - Semantische Audio-Suche der nÃ¤chsten Generation*