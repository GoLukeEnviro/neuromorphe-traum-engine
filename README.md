# ğŸµ Neuromorphe Traum-Engine v2.0

> *Ein KI-gestÃ¼tzter kreativer Partner fÃ¼r die Generierung von neuartigem Raw-Techno*
>
> *"Wo das Kollektive Unbewusste auf intelligente Dirigenten trifft"*

Die Neuromorphe Traum-Engine ist keine gewÃ¶hnliche Audio-Suchmaschine - sie ist ein semantisches KI-System, das die Grenzen zwischen menschlicher KreativitÃ¤t und maschineller Intuition verwischt. Basierend auf CLAP-Embeddings und modernster Audio-Technologie schafft sie einen luziden Traumzustand fÃ¼r Musikproduzenten.

## ğŸŒŒ Vision & Philosophie

### Das Kollektive Unbewusste
Unsere Engine greift auf ein semantisches GedÃ¤chtnis zu, das durch millionenfache Audio-Text-Korrelationen trainiert wurde. Jede Suche wird zu einer Reise durch das digitale Kollektivbewusstsein der elektronischen Musik.

### Intelligenter Dirigent
Der KI-Dirigent interpretiert nicht nur Begriffe, sondern versteht emotionale Nuancen, rhythmische Intentionen und klangliche AtmosphÃ¤ren. Er transformiert "energetic drum loop" in eine multidimensionale Suchanfrage, die Ã¼ber reine Metadaten hinausgeht.

### Luzides TrÃ¤umen
Produzenten kÃ¶nnen in Echtzeit durch ihre Audio-Bibliotheken navigieren, als wÃ¤ren sie in einem luziden Traum - jede Suchanfrage wird zu einer explorativen Reise durch unentdeckte Klanglandschaften.

## ğŸš€ Core Features

### ğŸ” Semantische Audio-Suche
- **NatÃ¼rlichsprachige Queries**: "dunkler, hypnotischer Techno-Kick mit industrieller Textur"
- **Multimodale Suche**: Kombination aus Text, Audio-Beispielen und Stimmungsanalyse
- **Stem-Mutation**: Generative Variationen gefundener Stems in Echtzeit

### ğŸ§  KI-Engine
- **CLAP-Embeddings**: State-of-the-art Audio-Text-Understanding via LAION CLAP
- **Adaptive Retrieval**: Lernende Suchalgorithmen basierend auf Nutzer-Feedback
- **Generatives Paradox**: KI-generierte Stem-VorschlÃ¤ge, die die ursprÃ¼ngliche Suche erweitern

### ğŸ›ï¸ Produktions-Workflow
- **Live-Session Integration**: Direkte Einbindung in DAW-Workflows via API
- **Stem-Kategorisierung**: Intelligente Klassifizierung (Kick, Bass, Hat, Percussion, FX)
- **QualitÃ¤ts-Scoring**: Automatische Bewertung von technischer und kreativer QualitÃ¤t

### ğŸ—ï¸ Architektur (Zwei-Framework-Prinzip)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  INTELLIGENTER DIRIGENT                      â”‚
â”‚                    (Live-Framework)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Streamlit Frontend    â”‚    FastAPI Backend    â”‚  Echtzeit- â”‚
â”‚  (Port 8501)          â”‚    (Port 8000)        â”‚  Audio     â”‚
â”‚                      â”‚                       â”‚  Engine    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   PRODUKTIONS-FABRIK                        â”‚
â”‚                  (Trainings-Framework)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CLAP Model Training  â”‚  Embeddings Pipeline  â”‚  Database  â”‚
â”‚  Stem Preprocessing   â”‚  Semantic Indexing    â”‚  SQLite    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ MVP-Fokus

Unsere aktuelle Mission ist die Validierung der kreativen Kernhypothese: **"Kann eine KI wirklich verstehen, was ein Produzent meint, wenn er 'einen treibenden Bass mit dunkler AtmosphÃ¤re' sucht?"**

### Erfolgsmetriken
- **Relevanz-Score**: >85% zufriedenstellende Ergebnisse bei semantischen Suchanfragen
- **Discovery-Rate**: >40% der Ergebnisse sind neue, unbekannte Stems
- **Workflow-Effizienz**: Reduktion der Suchzeit um 70% gegenÃ¼ber traditionellen Methoden

## ğŸ› ï¸ Technischer Stack

### Backend Core
- **FastAPI**: Moderne, asynchrone REST-API mit OpenAPI-Dokumentation
- **SQLAlchemy**: ORM fÃ¼r SQLite mit migrationsfÃ¤higer Architektur
- **Pydantic**: Type-safe Datenvalidierung und -serialisierung

### KI/ML Pipeline
- **LAION CLAP**: Contrastive Language-Audio Pre-training
- **Librosa**: Audio-Analyse und -verarbeitung
- **Demucs**: Source Separation fÃ¼r Stem-Extraktion
- **PyTorch**: Deep Learning Framework fÃ¼r Modelle

### Frontend & UX
- **Streamlit**: Rapid Prototyping fÃ¼r kreative Interfaces
- **WebSocket**: Echtzeit-Kommunikation fÃ¼r Live-Sessions
- **Responsive Design**: Mobile-first Ansatz fÃ¼r Studio- und Live-Einsatz

### Deployment & DevOps
- **Docker**: Containerisierung fÃ¼r beide Frameworks
- **Docker Compose**: Orchestrierung von Multi-Service-Setup
- **GitHub Actions**: CI/CD Pipeline mit automatisierten Tests

## ğŸ“¦ Quick Start

### âš¡ 30-Sekunden Setup (Docker)
```bash
git clone https://github.com/your-org/neuromorphe-traum-engine.git
cd neuromorphe-traum-engine
docker-compose up --build
```

### ğŸ”§ Lokale Entwicklung

#### Voraussetzungen
- Python 3.12+
- 8GB+ RAM (fÃ¼r CLAP-Modell)
- 10GB+ Speicherplatz

#### Schritt-fÃ¼r-Schritt
```bash
# 1. Repository klonen
git clone <repository-url>
cd neuromorphe-traum-engine

# 2. Virtuelle Umgebung erstellen
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. AbhÃ¤ngigkeiten installieren
pip install -r requirements.txt

# 4. Umgebungsvariablen konfigurieren
cp .env.example .env
# .env anpassen: DATABASE_URL, UPLOAD_DIR, etc.

# 5. Datenbank initialisieren
python -m src.cli.migrate_database

# 6. Backend starten
python -m uvicorn src.main:app --reload --host 0.0.0.0 --port 8000

# 7. Frontend starten (neues Terminal)
python -m streamlit run frontend/app.py --server.port 8501
```

### ğŸŒ Zugang nach Setup
- **Frontend**: http://localhost:8501
- **Backend API**: http://localhost:8000
- **API-Dokumentation**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/system/health

## ğŸ¯ Verwendung

### ğŸ” Semantische Suche - Die Magie entdecken

#### Beispiel-Suchanfragen
```bash
# Basis-Suche
curl "http://localhost:8000/api/v1/stems/search/?prompt=dark%20techno%20kick"

# Komplexe emotionale Suche
curl "http://localhost:8000/api/v1/stems/search/?prompt=melancholic%20bass%20with%20industrial%20texture"

# Tempo-basierte Suche
curl "http://localhost:8000/api/v1/stems/search/?prompt=fast%20percussion%20loop%20130bpm"

# Top-K Ergebnisse
curl "http://localhost:8000/api/v1/stems/search/?prompt=atmospheric%20pad&top_k=10"
```

#### Python Integration
```python
import requests

# Semantische Suche durchfÃ¼hren
response = requests.get(
    "http://localhost:8000/api/v1/stems/search/",
    params={
        "prompt": "driving techno bass with analog warmth",
        "category": "bass",
        "top_k": 5,
        "min_similarity": 0.7
    }
)

results = response.json()
for stem in results:
    print(f"ğŸµ {stem['filename']}")
    print(f"   Kategorie: {stem['category']}")
    print(f"   Ã„hnlichkeit: {stem['similarity']:.3f}")
    print(f"   Pfad: {stem['path']}")
```

### ğŸ›ï¸ Frontend - Der Luzide Navigator

#### Interface-Komponenten
1. **Search Portal**: NatÃ¼rlichsprachige Eingabe mit Live-VorschlÃ¤gen
2. **Stem Explorer**: Visuelle Navigation durch Klang-Universen
3. **Session Recorder**: Live-Aufnahme von Discovery-Sessions
4. **AI Assistant**: Kontextuelle Empfehlungen basierend auf Suchverhalten

#### Power-User Features
- **Batch Processing**: Mehrere Stems gleichzeitig analysieren
- **Custom Embeddings**: Eigene Modelle trainieren fÃ¼r spezifische Genres
- **Export Pipeline**: Direkte Integration mit DAWs via MIDI-Steuerung

## ğŸ—ï¸ Projektstruktur - Das neuronale Netzwerk

```
neuromorphe-traum-engine/
â”œâ”€â”€ ğŸ§  src/                          # Backend - Das neuronale Zentrum
â”‚   â”œâ”€â”€ api/                         # REST-API Endpunkte
â”‚   â”œâ”€â”€ core/                        # Kernkonfiguration & Logging
â”‚   â”œâ”€â”€ database/                    # SQLAlchemy Models & CRUD
â”‚   â”œâ”€â”€ schemas/                     # Pydantic Type-Definitionen
â”‚   â”œâ”€â”€ services/                    # Business Logic & KI-Services
â”‚   â”œâ”€â”€ audio/                       # Audio-Verarbeitung Pipeline
â”‚   â””â”€â”€ search/                      # Semantische Such-Engine
â”œâ”€â”€ ğŸ›ï¸ frontend/                     # Streamlit Interface
â”‚   â”œâ”€â”€ pages/                       # Multi-Page App Struktur
â”‚   â”œâ”€â”€ components/                  # Wiederverwendbare UI-Komponenten
â”‚   â””â”€â”€ utils/                       # Frontend-Hilfsfunktionen
â”œâ”€â”€ ğŸ—„ï¸ processed_database/           # SQLite + Embeddings
â”œâ”€â”€ ğŸ“ raw_construction_kits/        # Roh-Audio-Dateien
â”œâ”€â”€ ğŸ¯ models/                       # CLAP & Custom Modelle
â”œâ”€â”€ ğŸ³ docker/                       # Container-Konfiguration
â”œâ”€â”€ ğŸ“Š tests/                        # Test-Suite (pytest)
â””â”€â”€ ğŸ“ docs/                         # Technische Dokumentation
```

## ğŸ”§ Konfiguration & Anpassung

### Umgebungsvariablen (Environment Variables)

| Variable | Beschreibung | Standardwert | Entwicklung |
|----------|--------------|--------------|-------------|
| `PROJECT_NAME` | Anwendungsname | "Neuromorphe Traum-Engine v2.0" | Anpassen |
| `DATABASE_URL` | SQLite Pfad | "sqlite:///processed_database/stems.db" | Anpassen |
| `UPLOAD_DIR` | Audio-Uploads | "./raw_construction_kits" | Anpassen |
| `MODEL_CACHE_DIR` | CLAP Cache | "./models" | Anpassen |
| `API_BASE_URL` | Backend URL | "http://localhost:8000" | Anpassen |
| `LOG_LEVEL` | Logging Level | "INFO" | DEBUG fÃ¼r Dev |
| `MAX_FILE_SIZE` | Max Upload Size | "100MB" | ErhÃ¶hen |

### Advanced Configuration

#### Custom CLAP Model Training
```python
# src/services/training_service.py
class CustomCLAPTrainer:
    def __init__(self, dataset_path: str):
        self.dataset_path = dataset_path
        self.model_config = {
            'audio_encoder': 'HTSAT-base',
            'text_encoder': 'RoBERTa-base',
            'embed_dim': 512,
            'temperature': 0.07
        }
```

#### Stem-Kategorisierung erweitern
```python
# src/core/config.py
STEM_CATEGORIES = {
    'kick': ['kick', 'bassdrum', 'bd'],
    'snare': ['snare', 'clap', 'rimshot'],
    'hihat': ['hihat', 'hat', 'openhat', 'closedhat'],
    'bass': ['bass', 'sub', 'lowend'],
    'percussion': ['perc', 'shaker', 'conga', 'tom'],
    'fx': ['sweep', 'riser', 'impact', 'texture'],
    'synth': ['lead', 'pad', 'stab', 'chord'],
    'vocal': ['vox', 'voice', 'spoken', 'chant']
}
```

## ğŸ§ª Testing & QualitÃ¤tssicherung

### Test-Suite ausfÃ¼hren
```bash
# Alle Tests
pytest tests/ -v

# Nur API-Tests
pytest tests/test_api/ -v

# Mit Coverage
pytest tests/ --cov=src --cov-report=html

# Performance-Tests
pytest tests/test_performance.py -v
```

### Manuelle Tests
```bash
# Health Check
curl http://localhost:8000/system/health

# API-Dokumentation
curl http://localhost:8000/docs

# Suche testen
curl "http://localhost:8000/api/v1/stems/search/?prompt=test"
```

### Test-Daten erstellen
```bash
# Beispiel-Stems generieren
python -m src.cli.create_test_audio

# Test-Datenbank befÃ¼llen
python -m src.cli.migrate_database --test-data
```

## ğŸ“Š Performance & Skalierung

### System-Anforderungen
| Komponente | Minimum | Empfohlen | Cloud |
|------------|---------|-----------|-------|
| **CPU** | 4 Cores | 8 Cores | 16 Cores |
| **RAM** | 8GB | 16GB | 32GB |
| **Storage** | 50GB | 100GB SSD | 500GB SSD |
| **Network** | 10 Mbps | 100 Mbps | 1 Gbps |

### Performance-Metriken
- **CLAP-Modell Initialisierung**: 30-60 Sekunden
- **Embedding-Berechnung**: 1-2 Sekunden pro Audio-Datei
- **Such-Latenz**: 100-500ms (abhÃ¤ngig von Datenbank-GrÃ¶ÃŸe)
- **Memory-Footprint**: 2-4GB fÃ¼r CLAP-Modell
- **Datenbank-GrÃ¶ÃŸe**: ~1MB pro 1000 Stems

### Skalierungs-Strategien
1. **Phase 1**: SQLite â†’ PostgreSQL Migration
2. **Phase 2**: Single Instance â†’ Microservices
3. **Phase 3**: CPU â†’ GPU-Acceleration
4. **Phase 4**: On-Premise â†’ Cloud-Native

## ğŸ› Troubleshooting & Support

### HÃ¤ufige Probleme

#### 1. CLAP-Modell lÃ¤dt nicht
```bash
# Cache lÃ¶schen
rm -rf models/CLAP/
# Neu herunterladen beim nÃ¤chsten Start
```

#### 2. Datenbank-Lock Probleme
```bash
# SQLite Lock beheben
sqlite3 processed_database/stems.db "PRAGMA journal_mode=WAL;"
```

#### 3. Audio-Verarbeitung hÃ¤ngt
```bash
# Memory-Limit erhÃ¶hen
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
```

#### 4. Docker Container starten nicht
```bash
# Logs prÃ¼fen
docker-compose logs -f backend
docker-compose logs -f frontend

# Ports freigeben
sudo lsof -i :8000
sudo lsof -i :8501
```

### Debug-Modus aktivieren
```bash
# Backend mit Debug-Logging
LOG_LEVEL=DEBUG python -m uvicorn src.main:app --reload

# Frontend mit Debug-Modus
STREAMLIT_DEBUG=true python -m streamlit run frontend/app.py
```

### Support-KanÃ¤le
- **GitHub Issues**: Bug-Reports und Feature-Requests
- **Discord**: Community-Support und Diskussionen
- **Wiki**: Erweiterte Dokumentation und Tutorials

## ğŸš€ Roadmap & Future Vision

### Phase 1: MVP âœ…
- [x] Semantische Audio-Suche
- [x] CLAP-Integration
- [x] Basic Streamlit Frontend
- [x] Docker-Containerisierung

### Phase 2: Enhanced Intelligence ğŸš§
- [ ] Real-time Stem-Mutation
- [ ] Adaptive Learning from User Feedback
- [ ] Advanced Audio Analysis (BPM, Key, Mood)
- [ ] Multi-language Support

### Phase 3: Creative Ecosystem ğŸ¯
- [ ] DAW Plugin Integration (VST/AU)
- [ ] Collaborative Sessions
- [ ] Cloud-based Model Training
- [ ] Mobile Companion App

### Phase 4: Neural Synthesis ğŸš€
- [ ] Generative Stem Creation
- [ ] Style Transfer between Tracks
- [ ] AI-Powered Arrangement Suggestions
- [ ] Real-time Collaboration

## ğŸ¤ Contributing & Community

### Beitragen
1. **Fork** das Repository
2. **Feature Branch** erstellen: `feature/semantic-melody-search`
3. **Commit** mit Conventional Commits: `feat: add melody search capability`
4. **Push** zum Feature Branch
5. **Pull Request** erstellen

### Code-Standards
- **PEP 8** fÃ¼r Python
- **Type Hints** fÃ¼r alle Funktionen
- **Docstrings** fÃ¼r Ã¶ffentliche APIs
- **Tests** fÃ¼r neue Features
- **Performance** Ã¼ber Optimierung

### Community
- **Discord**: [Join our Server](https://discord.gg/neuromorphic)
- **Twitter**: [@NeuromorphicAI](https://twitter.com/neuromorphicai)
- **YouTube**: Tutorials und Live-Coding
- **Blog**: Deep-Dive Artikel zur KI-Musikproduktion

## ğŸ“„ Lizenz & Attribution

### Lizenz
```
MIT License - Siehe LICENSE Datei
```

### Drittanbieter
- **CLAP Model**: LAION-AI (MIT License)
- **Demucs**: Facebook Research (MIT License)
- **Librosa**: librosa.org (ISC License)
- **Streamlit**: Streamlit Inc (Apache 2.0)

### Zitierung
```bibtex
@software{neuromorphic_dream_engine,
  title={Neuromorphic Dream Engine: Semantic Audio Search for Electronic Music},
  author={Your Name},
  year={2024},
  url={https://github.com/your-org/neuromorphe-traum-engine}
}
```

---

<div align="center">

**ğŸµ *"Where neural networks dream in sound"* ğŸµ**

*Built with â¤ï¸ for the electronic music community*

[Getting Started](#-quick-start) â€¢ [Documentation](docs/) â€¢ [API Reference](http://localhost:8000/docs) â€¢ [Report Bug](../../issues)

</div>