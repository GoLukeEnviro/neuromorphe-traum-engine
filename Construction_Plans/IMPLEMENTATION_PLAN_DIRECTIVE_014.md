# üéµ IMPLEMENTIERUNGSPLAN: AGENTEN-DIREKTIVE 014

**Neuromorphe Traum-Engine v2.0 - Generatives Musik-Backend**

## üìã √úBERSICHT

Dieser Plan implementiert ein vollst√§ndiges generatives Musik-System basierend auf AGENTEN-DIREKTIVE 014. Das System kann aus Text-Prompts komplette Musik-Tracks generieren.

## üèóÔ∏è SYSTEM-ARCHITEKTUR

### Kernkomponenten
1. **Preprocessor**: Analysiert Audio-Stems und erstellt CLAP-Embeddings
2. **Arranger**: Generiert Track-Strukturpl√§ne aus Text-Prompts
3. **Renderer**: Montiert Stems zu finalen Audio-Tracks
4. **API**: REST-Endpunkte f√ºr Preprocessing und Track-Generierung

### Datenfluss
```
Text-Prompt ‚Üí Arranger ‚Üí Track-Plan ‚Üí Renderer ‚Üí Audio-Track
     ‚Üë                                    ‚Üì
  API-Input                        Generated WAV
```

## üìÅ VERZEICHNISSTRUKTUR

```
neuromorphe-traum-engine/
‚îú‚îÄ‚îÄ raw_construction_kits/          # Input: Audio-Stems
‚îú‚îÄ‚îÄ processed_database/             # Verarbeitete Daten
‚îÇ   ‚îú‚îÄ‚îÄ stems/                      # Stem-Metadaten
‚îÇ   ‚îî‚îÄ‚îÄ quarantine/                 # Fehlerhafte Dateien
‚îú‚îÄ‚îÄ generated_tracks/               # Output: Generierte Tracks
‚îú‚îÄ‚îÄ src/                           # Hauptquellcode
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ core/                      # Kernkonfiguration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ db/                        # Datenbanklogik
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ crud.py
‚îÇ   ‚îú‚îÄ‚îÄ services/                  # Business Logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.py        # NeuroAnalyzer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arranger.py           # Track-Strukturierung
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ renderer.py           # Audio-Montage
‚îÇ   ‚îú‚îÄ‚îÄ schemas/                   # Pydantic-Schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py
‚îÇ   ‚îú‚îÄ‚îÄ api/                       # REST-API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ endpoints.py
‚îÇ   ‚îî‚îÄ‚îÄ main.py                    # FastAPI-App
‚îî‚îÄ‚îÄ requirements.txt               # Dependencies
```

## üîß PHASE 1: PROJEKT-SETUP

### 1.1 Verzeichnisstruktur erstellen
- [x] Bestehende Struktur analysieren
- [ ] Fehlende Verzeichnisse erstellen
- [ ] Neue Struktur gem√§√ü Direktive anpassen

### 1.2 Dependencies aktualisieren
```txt
fastapi
uvicorn[standard]
sqlalchemy
pydantic
librosa
soundfile
numpy
laion-clap-pytorch
torch
scikit-learn
tqdm
pydantic-settings
```

## üóÑÔ∏è PHASE 2: DATEN-INFRASTRUKTUR

### 2.1 Datenbankmodelle (src/db/models.py)
```python
class Stem(Base):
    id: int (Primary Key)
    path: str (Dateipfad)
    filename: str
    category: str (kick, bass, hihat, etc.)
    tags: str (JSON-Array)
    bpm: float
    key: str
    duration: float
    embedding: bytes (CLAP-Embedding)
    created_at: datetime
    updated_at: datetime
```

### 2.2 CRUD-Operationen (src/db/crud.py)
- `create_stem()`
- `get_stem_by_id()`
- `search_stems_by_tags_and_category()` ‚≠ê **NEU f√ºr Arranger**
- `get_stems_by_category()`
- `update_stem()`
- `delete_stem()`

### 2.3 Pydantic-Schemas (src/schemas/schemas.py)
```python
class StemBase(BaseModel):
    path: str
    category: str
    tags: List[str]
    bpm: Optional[float]
    
class ArrangementPlan(BaseModel):  # ‚≠ê NEU
    bpm: int
    key: str
    structure: List[ArrangementSection]
    
class TrackGenerationRequest(BaseModel):  # ‚≠ê NEU
    prompt: str
    
class TrackGenerationResponse(BaseModel):  # ‚≠ê NEU
    track_path: str
    arrangement_plan: ArrangementPlan
```

## üß† PHASE 3: KREATIVE KERNLOGIK

### 3.1 Preprocessor Service (src/services/preprocessor.py)
**Basiert auf NeuroAnalyzer aus Direktive 006**

```python
class PreprocessorService:
    def __init__(self):
        # CLAP-Modell laden
        # Datenbank-Verbindung
        
    async def process_audio_files(self):
        # Batch-Verarbeitung mit Resume-Mechanismus
        # CLAP-Embeddings generieren
        # Metadaten extrahieren
        # In Datenbank speichern
```

### 3.2 Arranger Service (src/services/arranger.py) ‚≠ê **NEU**
**Intelligenter Track-Strukturierer**

```python
class ArrangerService:
    def __init__(self):
        # Datenbank-Zugriff √ºber CRUD
        
    def generate_arrangement_plan(self, prompt: str) -> dict:
        # 1. Prompt-Parsing (BPM, Genre, Stimmung)
        # 2. Track-Struktur generieren
        # 3. Stem-Queries definieren
        
        return {
            "bpm": 135,
            "key": "Am",
            "structure": [
                {
                    "section": "Intro",
                    "bars": 16,
                    "stem_queries": [
                        {"category": "atmo", "tags": ["dark"], "count": 1}
                    ]
                },
                {
                    "section": "Groove",
                    "bars": 64,
                    "stem_queries": [
                        {"category": "kick", "tags": ["aggressive"], "count": 1},
                        {"category": "bass", "tags": ["dark"], "count": 1}
                    ]
                }
            ]
        }
```

### 3.3 Renderer Service (src/services/renderer.py) ‚≠ê **NEU**
**Audio-Montage-Engine**

```python
class RendererService:
    def __init__(self):
        # Audio-Processing-Tools
        
    async def render_track(self, arrangement_plan: dict) -> str:
        # 1. Stems aus DB laden basierend auf Queries
        # 2. Audio-Timeline berechnen
        # 3. Stems zeitlich arrangieren
        # 4. Audio-Mixdown erstellen
        # 5. WAV-Datei speichern
        
        return "generated_tracks/track_20250126_150000.wav"
```

## üåê PHASE 4: API-INTEGRATION

### 4.1 API-Endpunkte (src/api/endpoints.py)

```python
@router.post("/preprocess")
async def preprocess_audio():
    # Startet Preprocessing asynchron
    
@router.post("/generate-track")  # ‚≠ê HAUPTFUNKTION
async def generate_track(request: TrackGenerationRequest):
    # 1. Arranger: Plan erstellen
    # 2. Renderer: Track generieren
    # 3. Pfad zur√ºckgeben
```

### 4.2 FastAPI-App (src/main.py)
```python
app = FastAPI(title="Neuromorphe Traum-Engine v2.0")
app.include_router(router, prefix="/api/v1")
```

## üéØ ERFOLGSKRITERIEN

### Technische Tests
- [ ] System startet fehlerfrei: `uvicorn src.main:app --reload`
- [ ] POST `/preprocess` verarbeitet Audio-Stems
- [ ] Datenbank wird korrekt gef√ºllt

### Funktionale Tests
- [ ] POST `/generate-track` mit Prompt: `{"prompt": "driving industrial techno 138 bpm"}`
- [ ] System generiert Track-Plan
- [ ] System findet passende Stems
- [ ] System erstellt WAV-Datei in `generated_tracks/`
- [ ] Generierte Datei ist abspielbar

### Qualit√§tskriterien
- [ ] Track entspricht musikalisch dem Prompt
- [ ] Audio-Qualit√§t ist hochwertig
- [ ] Timing und BPM sind korrekt
- [ ] Stems sind harmonisch arrangiert

## üîÑ IMPLEMENTIERUNGSREIHENFOLGE

1. **Setup & Struktur** (30 min)
   - Verzeichnisse erstellen
   - Dependencies aktualisieren

2. **Datenbank-Layer** (60 min)
   - Models erweitern
   - CRUD-Funktionen implementieren
   - Schemas definieren

3. **Preprocessor** (45 min)
   - Bestehenden Code refaktorisieren
   - In Service-Struktur integrieren

4. **Arranger Service** (90 min)
   - Prompt-Parser implementieren
   - Track-Struktur-Generator
   - Regel-basierte Logik

5. **Renderer Service** (120 min)
   - Stem-Suche implementieren
   - Audio-Timeline-Berechnung
   - Audio-Montage-Engine

6. **API-Integration** (45 min)
   - Endpunkte implementieren
   - Error-Handling
   - Response-Schemas

7. **Testing & Validation** (60 min)
   - Funktionale Tests
   - Audio-Qualit√§t pr√ºfen
   - Performance-Optimierung

**Gesamtzeit: ~7.5 Stunden**

## üö® KRITISCHE PUNKTE

1. **Audio-Synchronisation**: Stems m√ºssen zeitlich exakt aligniert werden
2. **BPM-Matching**: Tempo-Anpassung zwischen verschiedenen Stems
3. **Memory-Management**: Gro√üe Audio-Dateien effizient verarbeiten
4. **Error-Handling**: Robuste Fehlerbehandlung bei Audio-Processing
5. **Performance**: Rendering sollte < 30 Sekunden dauern

## üìä METRIKEN

- **Preprocessing-Zeit**: < 10s pro Stem
- **Arrangement-Zeit**: < 2s pro Prompt
- **Rendering-Zeit**: < 30s pro Track
- **Audio-Qualit√§t**: 44.1kHz, 16-bit WAV
- **Track-L√§nge**: 5-8 Minuten

---

**Status**: üîÑ Bereit zur Implementierung
**Priorit√§t**: üî• Hoch
**Komplexit√§t**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)